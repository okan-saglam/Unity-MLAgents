{
    "name": "root",
    "gauges": {
        "AgentControl.Policy.Entropy.mean": {
            "value": 1.476179599761963,
            "min": 1.4214012622833252,
            "max": 1.476179599761963,
            "count": 8
        },
        "AgentControl.Policy.Entropy.sum": {
            "value": 74746.3515625,
            "min": 71056.5234375,
            "max": 74746.3515625,
            "count": 8
        },
        "AgentControl.Environment.EpisodeLength.mean": {
            "value": 816.2222222222222,
            "min": 195.6195652173913,
            "max": 998.8510638297872,
            "count": 8
        },
        "AgentControl.Environment.EpisodeLength.sum": {
            "value": 44076.0,
            "min": 17997.0,
            "max": 50574.0,
            "count": 8
        },
        "AgentControl.Step.mean": {
            "value": 399960.0,
            "min": 49961.0,
            "max": 399960.0,
            "count": 8
        },
        "AgentControl.Step.sum": {
            "value": 399960.0,
            "min": 49961.0,
            "max": 399960.0,
            "count": 8
        },
        "AgentControl.Policy.ExtrinsicValueEstimate.mean": {
            "value": -5.804454803466797,
            "min": -38.15530776977539,
            "max": -1.3763688802719116,
            "count": 8
        },
        "AgentControl.Policy.ExtrinsicValueEstimate.sum": {
            "value": -4701.6083984375,
            "min": -30982.109375,
            "max": -1132.7515869140625,
            "count": 8
        },
        "AgentControl.Environment.CumulativeReward.mean": {
            "value": 1.5555555555555556,
            "min": -0.6086956521739131,
            "max": 2.046153846153846,
            "count": 8
        },
        "AgentControl.Environment.CumulativeReward.sum": {
            "value": 84.0,
            "min": -56.0,
            "max": 133.0,
            "count": 8
        },
        "AgentControl.Policy.ExtrinsicReward.mean": {
            "value": 1.5555555555555556,
            "min": -0.6086956521739131,
            "max": 2.046153846153846,
            "count": 8
        },
        "AgentControl.Policy.ExtrinsicReward.sum": {
            "value": 84.0,
            "min": -56.0,
            "max": 133.0,
            "count": 8
        },
        "AgentControl.Losses.PolicyLoss.mean": {
            "value": 0.07421601212214832,
            "min": 0.049078331109679615,
            "max": 0.07774454011271396,
            "count": 8
        },
        "AgentControl.Losses.PolicyLoss.sum": {
            "value": 0.3710800606107416,
            "min": 0.19631332443871846,
            "max": 0.38872270056356983,
            "count": 8
        },
        "AgentControl.Losses.ValueLoss.mean": {
            "value": 97.68781858563423,
            "min": 8.028781256632117,
            "max": 13124.099361252785,
            "count": 8
        },
        "AgentControl.Losses.ValueLoss.sum": {
            "value": 488.43909292817114,
            "min": 32.11512502652847,
            "max": 52496.39744501114,
            "count": 8
        },
        "AgentControl.Policy.LearningRate.mean": {
            "value": 7.685779438075998e-05,
            "min": 7.685779438075998e-05,
            "max": 0.0002838441053853,
            "count": 8
        },
        "AgentControl.Policy.LearningRate.sum": {
            "value": 0.00038428897190379994,
            "min": 0.00038428897190379994,
            "max": 0.001280319073227,
            "count": 8
        },
        "AgentControl.Policy.Epsilon.mean": {
            "value": 0.12561923999999997,
            "min": 0.12561923999999997,
            "max": 0.19461470000000003,
            "count": 8
        },
        "AgentControl.Policy.Epsilon.sum": {
            "value": 0.6280961999999999,
            "min": 0.5395975999999999,
            "max": 0.9267730000000001,
            "count": 8
        },
        "AgentControl.Policy.Beta.mean": {
            "value": 0.0012884000760000004,
            "min": 0.0012884000760000004,
            "max": 0.00473127353,
            "count": 8
        },
        "AgentControl.Policy.Beta.sum": {
            "value": 0.006442000380000002,
            "min": 0.006442000380000002,
            "max": 0.0213459727,
            "count": 8
        },
        "AgentControl.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 8
        },
        "AgentControl.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 8
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1751305013",
        "python_version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\user\\Desktop\\MyGames\\MLAgent\\MLvenv\\Scripts\\mlagents-learn --run-id =RayCastRun2",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.7.1+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1751305354"
    },
    "total": 341.3989571,
    "count": 1,
    "self": 0.014178800000024694,
    "children": {
        "run_training.setup": {
            "total": 0.038766399999999646,
            "count": 1,
            "self": 0.038766399999999646
        },
        "TrainerController.start_learning": {
            "total": 341.3460119,
            "count": 1,
            "self": 0.1999244999993266,
            "children": {
                "TrainerController._reset_env": {
                    "total": 16.073408999999998,
                    "count": 1,
                    "self": 16.073408999999998
                },
                "TrainerController.advance": {
                    "total": 324.8390560000007,
                    "count": 6778,
                    "self": 0.19423330000290662,
                    "children": {
                        "env_step": {
                            "total": 194.8862195999981,
                            "count": 6778,
                            "self": 182.8811553999989,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 11.89381810000016,
                                    "count": 6778,
                                    "self": 0.6666320000001065,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 11.227186100000054,
                                            "count": 6404,
                                            "self": 11.227186100000054
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.11124609999904678,
                                    "count": 6777,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 327.49666190000147,
                                            "count": 6777,
                                            "is_parallel": true,
                                            "self": 170.7952106000023,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0022159999999988855,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0011137999999988324,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0011022000000000531,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.0011022000000000531
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 156.69923529999917,
                                                    "count": 6777,
                                                    "is_parallel": true,
                                                    "self": 4.555622899998781,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 6.279267699999085,
                                                            "count": 6777,
                                                            "is_parallel": true,
                                                            "self": 6.279267699999085
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 135.63639540000037,
                                                            "count": 6777,
                                                            "is_parallel": true,
                                                            "self": 135.63639540000037
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 10.227949300000954,
                                                            "count": 6777,
                                                            "is_parallel": true,
                                                            "self": 2.4041563000015813,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 7.823792999999373,
                                                                    "count": 27108,
                                                                    "is_parallel": true,
                                                                    "self": 7.823792999999373
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 129.75860309999973,
                            "count": 6777,
                            "self": 0.46934840000054123,
                            "children": {
                                "process_trajectory": {
                                    "total": 33.893998899999175,
                                    "count": 6777,
                                    "self": 33.893998899999175
                                },
                                "_update_policy": {
                                    "total": 95.39525580000002,
                                    "count": 40,
                                    "self": 69.56696449999988,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 25.828291300000135,
                                            "count": 1203,
                                            "self": 25.828291300000135
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.1000000199601345e-06,
                    "count": 1,
                    "self": 1.1000000199601345e-06
                },
                "TrainerController._save_models": {
                    "total": 0.2336212999999816,
                    "count": 1,
                    "self": 0.02910929999995915,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.20451200000002245,
                            "count": 1,
                            "self": 0.20451200000002245
                        }
                    }
                }
            }
        }
    }
}